"""
Elysia Engine Evaluation Module
================================

êµ¬ì¡° ì¶”ì¶œ, ê´€ê³„ì„± ë¶„ì„, ê°ê´€ì  í‰ê°€ ì§€í‘œ ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ ì›ë³¸ Elysia ì €ì¥ì†Œì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê³ ,
ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì‰½ê²Œ ì´í•´í•˜ê³  ê³µìœ í•  ìˆ˜ ìˆë„ë¡ í‰ê°€ ì§€í‘œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

í•µì‹¬ ê¸°ëŠ¥:
1. êµ¬ì¡° ì¶”ì¶œ (Structure Extraction): ëª¨ë“ˆ ê°„ ê´€ê³„ì„± ë¶„ì„
2. ê´€ê³„ì„± í‰ê°€ (Relationship Evaluation): ì˜ì¡´ì„± ë° ì—°ê²°ì„± ë¶„ì„
3. í’ˆì§ˆ ì§€í‘œ (Quality Metrics): ì½”ë“œ í’ˆì§ˆ ë° ì•„í‚¤í…ì²˜ í‰ê°€
4. ê°œì„  ì‚¬í•­ ë„ì¶œ (Improvement Suggestions): ìë™í™”ëœ ë³´ì™„ì  ë¶„ì„
5. ë³µì¡ë„ ë¶„ì„ (Complexity Analysis): ìˆœí™˜ ë³µì¡ë„ ë° ë©”íŠ¸ë¦­ ê³„ì‚°
"""

from __future__ import annotations

import ast
import json
import os
import codecs
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Set, Tuple
from datetime import datetime

from .logging_config import get_logger

logger = get_logger(__name__)


class ModuleCategory(Enum):
    """ëª¨ë“ˆ ì¹´í…Œê³ ë¦¬"""
    CORE = "core"           # í•µì‹¬ ëª¨ë“ˆ (tensor, math_utils)
    PHYSICS = "physics"     # ë¬¼ë¦¬ ì‹œìŠ¤í…œ
    CONSCIOUSNESS = "consciousness"  # ì˜ì‹ ì‹œìŠ¤í…œ
    SYSTEM = "system"       # ECS ì‹œìŠ¤í…œ
    INTEGRATION = "integration"  # í†µí•© ëª¨ë“ˆ
    UTILITY = "utility"     # ìœ í‹¸ë¦¬í‹°


class QualityLevel(Enum):
    """í’ˆì§ˆ ìˆ˜ì¤€"""
    EXCELLENT = "â­â­â­â­â­"
    GOOD = "â­â­â­â­"
    MODERATE = "â­â­â­"
    NEEDS_IMPROVEMENT = "â­â­"
    CRITICAL = "â­"


@dataclass
class ComplexityMetrics:
    """ë³µì¡ë„ ë©”íŠ¸ë¦­"""
    cyclomatic_complexity: int = 0  # ìˆœí™˜ ë³µì¡ë„
    cognitive_complexity: int = 0   # ì¸ì§€ ë³µì¡ë„
    max_nesting_depth: int = 0      # ìµœëŒ€ ì¤‘ì²© ê¹Šì´
    avg_function_length: float = 0.0  # í‰ê·  í•¨ìˆ˜ ê¸¸ì´


@dataclass
class ModuleInfo:
    """ëª¨ë“ˆ ì •ë³´"""
    name: str
    path: str
    category: ModuleCategory
    
    # ë©”íŠ¸ë¦­
    lines_of_code: int = 0
    class_count: int = 0
    function_count: int = 0
    docstring_coverage: float = 0.0
    
    # ë³µì¡ë„ ë©”íŠ¸ë¦­
    complexity: ComplexityMetrics = field(default_factory=ComplexityMetrics)
    
    # ê´€ê³„ì„±
    imports: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    dependents: List[str] = field(default_factory=list)
    
    # í’ˆì§ˆ ì ìˆ˜
    quality_score: float = 0.0
    
    # ì„¤ëª…
    description: str = ""


@dataclass
class RelationshipEdge:
    """ëª¨ë“ˆ ê°„ ê´€ê³„"""
    source: str
    target: str
    relationship_type: str  # 'imports', 'inherits', 'uses', 'resonates'
    strength: float = 1.0  # ì—°ê²° ê°•ë„ (0.0 ~ 1.0)


@dataclass
class EvaluationResult:
    """í‰ê°€ ê²°ê³¼"""
    timestamp: datetime = field(default_factory=datetime.now)
    
    # ì „ì²´ ì ìˆ˜
    overall_score: float = 0.0
    quality_level: QualityLevel = QualityLevel.MODERATE
    
    # ì„¸ë¶€ ì ìˆ˜
    architecture_score: float = 0.0
    code_quality_score: float = 0.0
    documentation_score: float = 0.0
    test_coverage_score: float = 0.0
    connectivity_score: float = 0.0
    
    # ëª¨ë“ˆ ëª©ë¡
    modules: List[ModuleInfo] = field(default_factory=list)
    
    # ê´€ê³„ì„± ê·¸ë˜í”„
    relationships: List[RelationshipEdge] = field(default_factory=list)
    
    # ê°•ì 
    strengths: List[str] = field(default_factory=list)
    
    # ê°œì„  ì‚¬í•­
    improvements: List[Dict[str, Any]] = field(default_factory=list)
    
    # ìš”ì•½
    summary: str = ""


class StructureExtractor:
    """êµ¬ì¡° ì¶”ì¶œê¸°"""
    
    def __init__(self, root_path: str):
        """
        Args:
            root_path: ì €ì¥ì†Œ ë£¨íŠ¸ ê²½ë¡œ
        """
        self.root_path = root_path
        self.modules: Dict[str, ModuleInfo] = {}
        self.relationships: List[RelationshipEdge] = []
        
    def extract(self) -> Dict[str, ModuleInfo]:
        """ì „ì²´ êµ¬ì¡° ì¶”ì¶œ"""
        # 1. elysia_engine ë¶„ì„
        engine_path = os.path.join(self.root_path, "elysia_engine")
        if os.path.exists(engine_path):
            self._analyze_package(engine_path, "elysia_engine")
            
        # 2. elysia_core ë¶„ì„
        core_path = os.path.join(self.root_path, "elysia_core")
        if os.path.exists(core_path):
            self._analyze_package(core_path, "elysia_core")
            
        # 3. ê´€ê³„ì„± ë¶„ì„
        self._analyze_relationships()
        
        return self.modules
    
    def _analyze_package(self, package_path: str, package_name: str) -> None:
        """íŒ¨í‚¤ì§€ ë¶„ì„"""
        for item in os.listdir(package_path):
            item_path = os.path.join(package_path, item)
            
            if item.endswith(".py") and not item.startswith("__"):
                module_name = f"{package_name}.{item[:-3]}"
                self._analyze_module(item_path, module_name)
                
            elif os.path.isdir(item_path) and not item.startswith("__"):
                subpackage_name = f"{package_name}.{item}"
                self._analyze_package(item_path, subpackage_name)
    
    def _read_file_content(self, file_path: str) -> str:
        """íŒŒì¼ ë‚´ìš© ì½ê¸° (BOM ë¬¸ì ì²˜ë¦¬ í¬í•¨)"""
        # ë¨¼ì € utf-8-sigë¡œ ì‹œë„ (BOM ìë™ ì²˜ë¦¬)
        try:
            with codecs.open(file_path, "r", encoding="utf-8-sig") as f:
                return f.read()
        except UnicodeDecodeError:
            pass
        
        # utf-8ë¡œ ì‹œë„
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                # BOM ìˆ˜ë™ ì œê±°
                if content.startswith('\ufeff'):
                    content = content[1:]
                return content
        except UnicodeDecodeError:
            pass
        
        # latin-1ë¡œ í´ë°±
        with open(file_path, "r", encoding="latin-1") as f:
            return f.read()
    
    def _analyze_module(self, file_path: str, module_name: str) -> None:
        """ëª¨ë“ˆ ë¶„ì„"""
        try:
            content = self._read_file_content(file_path)
                
            tree = ast.parse(content)
            
            # ê¸°ë³¸ ì •ë³´
            lines = content.split("\n")
            loc = len([l for l in lines if l.strip() and not l.strip().startswith("#")])
            
            # í´ë˜ìŠ¤/í•¨ìˆ˜ ì¹´ìš´íŠ¸
            class_count = sum(1 for node in ast.walk(tree) if isinstance(node, ast.ClassDef))
            func_count = sum(1 for node in ast.walk(tree) if isinstance(node, ast.FunctionDef))
            
            # ë…ìŠ¤íŠ¸ë§ ì»¤ë²„ë¦¬ì§€
            docstring_coverage = self._calculate_docstring_coverage(tree)
            
            # imports ì¶”ì¶œ
            imports = self._extract_imports(tree)
            
            # ì¹´í…Œê³ ë¦¬ ê²°ì •
            category = self._determine_category(module_name, content)
            
            # ì„¤ëª… ì¶”ì¶œ (ëª¨ë“ˆ ë…ìŠ¤íŠ¸ë§)
            description = ast.get_docstring(tree) or ""
            if len(description) > 200:
                description = description[:200] + "..."
            
            # ë³µì¡ë„ ë¶„ì„
            complexity = self._calculate_complexity(tree)
                
            module_info = ModuleInfo(
                name=module_name,
                path=file_path,
                category=category,
                lines_of_code=loc,
                class_count=class_count,
                function_count=func_count,
                docstring_coverage=docstring_coverage,
                complexity=complexity,
                imports=imports,
                description=description
            )
            
            self.modules[module_name] = module_info
            
        except Exception as e:
            logger.warning(f"ëª¨ë“ˆ ë¶„ì„ ì‹¤íŒ¨ {module_name}: {e}")
    
    def _calculate_complexity(self, tree: ast.AST) -> ComplexityMetrics:
        """ë³µì¡ë„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        total_cyclomatic = 0
        total_cognitive = 0
        max_depth = 0
        function_lengths: List[int] = []
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                # ìˆœí™˜ ë³µì¡ë„ ê³„ì‚°
                cyclomatic = self._calculate_cyclomatic_complexity(node)
                total_cyclomatic += cyclomatic
                
                # ì¸ì§€ ë³µì¡ë„ ê³„ì‚°
                cognitive = self._calculate_cognitive_complexity(node)
                total_cognitive += cognitive
                
                # í•¨ìˆ˜ ê¸¸ì´
                if hasattr(node, 'end_lineno') and hasattr(node, 'lineno'):
                    func_length = node.end_lineno - node.lineno + 1
                    function_lengths.append(func_length)
                
                # ì¤‘ì²© ê¹Šì´
                depth = self._calculate_nesting_depth(node)
                max_depth = max(max_depth, depth)
        
        avg_func_length = sum(function_lengths) / len(function_lengths) if function_lengths else 0.0
        
        return ComplexityMetrics(
            cyclomatic_complexity=total_cyclomatic,
            cognitive_complexity=total_cognitive,
            max_nesting_depth=max_depth,
            avg_function_length=avg_func_length
        )
    
    def _calculate_cyclomatic_complexity(self, node: ast.AST) -> int:
        """ìˆœí™˜ ë³µì¡ë„ ê³„ì‚° (McCabe)"""
        complexity = 1  # ê¸°ë³¸ ê²½ë¡œ
        
        # ì¤‘ì²©ëœ í•¨ìˆ˜ ì •ì˜ëŠ” ì œì™¸í•˜ê³  ìˆœíšŒ
        for child in ast.iter_child_nodes(node):
            # ì¤‘ì²© í•¨ìˆ˜ëŠ” ë³„ë„ë¡œ ë¶„ì„ë˜ë¯€ë¡œ ê±´ë„ˆëœ€
            if isinstance(child, (ast.FunctionDef, ast.AsyncFunctionDef)):
                continue
            
            # í˜„ì¬ ë…¸ë“œì˜ ë³µì¡ë„ ê³„ì‚°
            complexity += self._count_complexity_nodes(child)
        
        return complexity
    
    def _count_complexity_nodes(self, node: ast.AST) -> int:
        """ë³µì¡ë„ì— ê¸°ì—¬í•˜ëŠ” ë…¸ë“œ ê°œìˆ˜ ê³„ì‚° (ì¬ê·€ì ìœ¼ë¡œ, ì¤‘ì²© í•¨ìˆ˜ ì œì™¸)"""
        count = 0
        
        # ë¶„ê¸°ë¬¸
        if isinstance(node, (ast.If, ast.While, ast.For, ast.AsyncFor)):
            count += 1
        # ì˜ˆì™¸ ì²˜ë¦¬
        elif isinstance(node, ast.ExceptHandler):
            count += 1
        # ë…¼ë¦¬ ì—°ì‚°ì
        elif isinstance(node, ast.BoolOp):
            count += len(node.values) - 1
        # ì¡°ê±´ë¶€ í‘œí˜„ì‹
        elif isinstance(node, ast.IfExp):
            count += 1
        # ì»´í”„ë¦¬í—¨ì…˜
        elif isinstance(node, (ast.ListComp, ast.SetComp, ast.DictComp, ast.GeneratorExp)):
            count += sum(1 for _ in node.generators)
        
        # ìì‹ ë…¸ë“œ ì¬ê·€ ìˆœíšŒ (ì¤‘ì²© í•¨ìˆ˜ ì œì™¸)
        for child in ast.iter_child_nodes(node):
            if not isinstance(child, (ast.FunctionDef, ast.AsyncFunctionDef)):
                count += self._count_complexity_nodes(child)
        
        return count
    
    def _calculate_cognitive_complexity(self, node: ast.AST, nesting: int = 0) -> int:
        """ì¸ì§€ ë³µì¡ë„ ê³„ì‚°"""
        complexity = 0
        
        for child in ast.iter_child_nodes(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1 + nesting
                complexity += self._calculate_cognitive_complexity(child, nesting + 1)
            elif isinstance(child, (ast.FunctionDef, ast.AsyncFunctionDef, ast.Lambda)):
                # ì¤‘ì²© í•¨ìˆ˜ëŠ” nestingì„ ì¦ê°€ì‹œí‚¤ì§€ ì•Šê³  ë³„ë„ë¡œ ë¶„ì„
                complexity += self._calculate_cognitive_complexity(child, 0)
            elif isinstance(child, ast.BoolOp):
                complexity += 1
            else:
                complexity += self._calculate_cognitive_complexity(child, nesting)
        
        return complexity
    
    def _calculate_nesting_depth(self, node: ast.AST, current_depth: int = 0) -> int:
        """ìµœëŒ€ ì¤‘ì²© ê¹Šì´ ê³„ì‚°"""
        max_depth = current_depth
        
        for child in ast.iter_child_nodes(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor, ast.With, ast.Try)):
                child_depth = self._calculate_nesting_depth(child, current_depth + 1)
                max_depth = max(max_depth, child_depth)
            else:
                child_depth = self._calculate_nesting_depth(child, current_depth)
                max_depth = max(max_depth, child_depth)
        
        return max_depth
    
    def _calculate_docstring_coverage(self, tree: ast.AST) -> float:
        """ë…ìŠ¤íŠ¸ë§ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°"""
        total = 0
        documented = 0
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.ClassDef, ast.FunctionDef)):
                total += 1
                if ast.get_docstring(node):
                    documented += 1
                    
        return documented / total if total > 0 else 0.0
    
    def _extract_imports(self, tree: ast.AST) -> List[str]:
        """import ì¶”ì¶œ"""
        imports = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)
                    
        return imports
    
    def _determine_category(self, module_name: str, content: str) -> ModuleCategory:
        """ëª¨ë“ˆ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        name_lower = module_name.lower()
        
        if any(x in name_lower for x in ["tensor", "math_utils", "config"]):
            return ModuleCategory.CORE
        elif any(x in name_lower for x in ["physics", "gauge", "thermodynamics"]):
            return ModuleCategory.PHYSICS
        elif any(x in name_lower for x in ["consciousness", "soul", "emotion", "thought"]):
            return ModuleCategory.CONSCIOUSNESS
        elif "system" in name_lower or "elysia_engine.systems" in module_name:
            return ModuleCategory.SYSTEM
        elif any(x in name_lower for x in ["ether", "yggdrasil", "controller"]):
            return ModuleCategory.INTEGRATION
        else:
            return ModuleCategory.UTILITY
    
    def _analyze_relationships(self) -> None:
        """ê´€ê³„ì„± ë¶„ì„"""
        for module_name, module_info in self.modules.items():
            for imp in module_info.imports:
                # ë‚´ë¶€ ëª¨ë“ˆì— ëŒ€í•œ ì˜ì¡´ì„±ë§Œ ì¶”ì 
                for target_name in self.modules.keys():
                    if imp in target_name or target_name.endswith(f".{imp}"):
                        edge = RelationshipEdge(
                            source=module_name,
                            target=target_name,
                            relationship_type="imports",
                            strength=1.0
                        )
                        self.relationships.append(edge)
                        module_info.dependencies.append(target_name)
                        
                        # ì—­ì°¸ì¡° ì„¤ì •
                        if target_name in self.modules:
                            self.modules[target_name].dependents.append(module_name)


class QualityEvaluator:
    """í’ˆì§ˆ í‰ê°€ê¸°"""
    
    def __init__(self, modules: Dict[str, ModuleInfo], relationships: List[RelationshipEdge]):
        self.modules = modules
        self.relationships = relationships
        
    def evaluate(self) -> EvaluationResult:
        """í’ˆì§ˆ í‰ê°€ ìˆ˜í–‰"""
        result = EvaluationResult()
        result.modules = list(self.modules.values())
        result.relationships = self.relationships
        
        # 1. ì•„í‚¤í…ì²˜ ì ìˆ˜
        result.architecture_score = self._evaluate_architecture()
        
        # 2. ì½”ë“œ í’ˆì§ˆ ì ìˆ˜
        result.code_quality_score = self._evaluate_code_quality()
        
        # 3. ë¬¸ì„œí™” ì ìˆ˜
        result.documentation_score = self._evaluate_documentation()
        
        # 4. ì—°ê²°ì„± ì ìˆ˜
        result.connectivity_score = self._evaluate_connectivity()
        
        # 5. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ (í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¶„ì„)
        result.test_coverage_score = self._estimate_test_coverage()
        
        # 6. ì „ì²´ ì ìˆ˜ ê³„ì‚°
        result.overall_score = (
            result.architecture_score * 0.25 +
            result.code_quality_score * 0.25 +
            result.documentation_score * 0.2 +
            result.test_coverage_score * 0.2 +
            result.connectivity_score * 0.1
        )
        
        # 7. í’ˆì§ˆ ìˆ˜ì¤€ ê²°ì •
        result.quality_level = self._determine_quality_level(result.overall_score)
        
        # 8. ê°•ì  ë¶„ì„
        result.strengths = self._analyze_strengths(result)
        
        # 9. ê°œì„  ì‚¬í•­ ë„ì¶œ
        result.improvements = self._analyze_improvements()
        
        # 10. ìš”ì•½ ìƒì„±
        result.summary = self._generate_summary(result)
        
        return result
    
    def _evaluate_architecture(self) -> float:
        """ì•„í‚¤í…ì²˜ í‰ê°€"""
        score = 0.0
        
        # 1. ëª¨ë“ˆí™” ìˆ˜ì¤€ (ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„±)
        categories = set(m.category for m in self.modules.values())
        score += min(len(categories) / 6.0, 1.0) * 0.3
        
        # 2. ì˜ì¡´ì„± êµ¬ì¡° (ìˆœí™˜ ì˜ì¡´ì„± ì—†ìŒ = ì¢‹ìŒ)
        has_cycles = self._detect_cycles()
        score += 0.3 if not has_cycles else 0.1
        
        # 3. í•µì‹¬-ì£¼ë³€ë¶€ ë¶„ë¦¬
        core_modules = [m for m in self.modules.values() if m.category == ModuleCategory.CORE]
        if core_modules:
            avg_dependents = sum(len(m.dependents) for m in core_modules) / len(core_modules)
            score += min(avg_dependents / 5.0, 1.0) * 0.2
            
        # 4. System íŒ¨í„´ ì ìš©
        system_modules = [m for m in self.modules.values() if m.category == ModuleCategory.SYSTEM]
        score += min(len(system_modules) / 5.0, 1.0) * 0.2
        
        return min(score, 1.0)
    
    def _detect_cycles(self) -> bool:
        """ìˆœí™˜ ì˜ì¡´ì„± íƒì§€"""
        # ê°„ë‹¨í•œ DFS ê¸°ë°˜ ìˆœí™˜ íƒì§€
        visited = set()
        rec_stack = set()
        
        def dfs(node: str) -> bool:
            visited.add(node)
            rec_stack.add(node)
            
            if node in self.modules:
                for dep in self.modules[node].dependencies:
                    if dep not in visited:
                        if dfs(dep):
                            return True
                    elif dep in rec_stack:
                        return True
                        
            rec_stack.discard(node)
            return False
            
        for module in self.modules:
            if module not in visited:
                if dfs(module):
                    return True
        return False
    
    def _evaluate_code_quality(self) -> float:
        """ì½”ë“œ í’ˆì§ˆ í‰ê°€"""
        if not self.modules:
            return 0.0
            
        scores = []
        
        for module in self.modules.values():
            module_score = 0.0
            
            # 1. ì ì ˆí•œ ëª¨ë“ˆ í¬ê¸° (50-500 LOC = ì¢‹ìŒ)
            if 50 <= module.lines_of_code <= 500:
                module_score += 0.25
            elif module.lines_of_code < 50:
                module_score += 0.15
            else:
                module_score += 0.1
                
            # 2. í´ë˜ìŠ¤/í•¨ìˆ˜ ë¹„ìœ¨
            if module.class_count > 0 and module.function_count > 0:
                module_score += 0.25
            
            # 3. ë…ìŠ¤íŠ¸ë§ ì»¤ë²„ë¦¬ì§€
            module_score += module.docstring_coverage * 0.3
            
            # 4. ë³µì¡ë„ í‰ê°€ (ë‚®ì€ ë³µì¡ë„ = ë†’ì€ ì ìˆ˜)
            complexity_score = 0.0
            if module.complexity.cyclomatic_complexity > 0:
                # ìˆœí™˜ ë³µì¡ë„ê°€ 10 ì´í•˜ë©´ ì¢‹ìŒ, 20 ì´ìƒì´ë©´ ë‚˜ì¨
                if module.complexity.cyclomatic_complexity <= 10:
                    complexity_score = 0.2
                elif module.complexity.cyclomatic_complexity <= 20:
                    complexity_score = 0.1
                else:
                    complexity_score = 0.05
            else:
                complexity_score = 0.15  # ë³µì¡ë„ ì •ë³´ ì—†ìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜
            module_score += complexity_score
            
            scores.append(module_score)
            module.quality_score = module_score
            
        return sum(scores) / len(scores)
    
    def _evaluate_documentation(self) -> float:
        """ë¬¸ì„œí™” í‰ê°€"""
        total_coverage = sum(m.docstring_coverage for m in self.modules.values())
        avg_coverage = total_coverage / len(self.modules) if self.modules else 0.0
        
        # ëª¨ë“ˆ ì„¤ëª…ì´ ìˆëŠ” ë¹„ìœ¨
        has_description = sum(1 for m in self.modules.values() if m.description)
        description_ratio = has_description / len(self.modules) if self.modules else 0.0
        
        return (avg_coverage + description_ratio) / 2
    
    def _evaluate_connectivity(self) -> float:
        """ì—°ê²°ì„± í‰ê°€"""
        if not self.modules:
            return 0.0
            
        # 1. í‰ê·  ì—°ê²° ìˆ˜
        avg_connections = len(self.relationships) / len(self.modules)
        connection_score = min(avg_connections / 3.0, 1.0) * 0.5
        
        # 2. ê³ ë¦½ëœ ëª¨ë“ˆ ì—†ìŒ
        connected_modules = set()
        for edge in self.relationships:
            connected_modules.add(edge.source)
            connected_modules.add(edge.target)
        isolation_score = len(connected_modules) / len(self.modules) * 0.5
        
        return connection_score + isolation_score
    
    def _estimate_test_coverage(self) -> float:
        """í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¶”ì •"""
        # í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¶„ì„
        test_count = 0
        tested_modules = set()
        
        # ëª¨ë“ˆ ì´ë¦„ì—ì„œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ì´ë¦„ ì¶”ì¶œ
        module_names = set()
        for name in self.modules.keys():
            short_name = name.split(".")[-1]
            module_names.add(short_name)
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ íƒìƒ‰ (ìƒëŒ€ ê²½ë¡œë¡œ tests/ ë””ë ‰í† ë¦¬ ì°¾ê¸°)
        for module_name in self.modules.keys():
            if "elysia_engine" in module_name or "elysia_core" in module_name:
                module_path = self.modules[module_name].path
                # í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ì¶”ì •
                project_root = os.path.dirname(os.path.dirname(module_path))
                test_dir = os.path.join(project_root, "tests")
                
                if os.path.exists(test_dir):
                    for test_file in os.listdir(test_dir):
                        if test_file.startswith("test_") and test_file.endswith(".py"):
                            test_count += 1
                            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì´ë¦„ì—ì„œ ëª¨ë“ˆ ì´ë¦„ ì¶”ì¶œ
                            module_tested = test_file[5:-3]  # test_xxx.py -> xxx
                            if module_tested in module_names:
                                tested_modules.add(module_tested)
                break
        
        if not self.modules:
            return 0.0
        
        # í…ŒìŠ¤íŠ¸ëœ ëª¨ë“ˆ ë¹„ìœ¨ ê³„ì‚°
        coverage_ratio = len(tested_modules) / len(module_names) if module_names else 0.0
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤
        test_bonus = min(test_count / 20.0, 0.3)  # ìµœëŒ€ 0.3 ë³´ë„ˆìŠ¤
        
        return min(coverage_ratio * 0.7 + test_bonus, 1.0)
    
    def _determine_quality_level(self, score: float) -> QualityLevel:
        """í’ˆì§ˆ ìˆ˜ì¤€ ê²°ì •"""
        if score >= 0.9:
            return QualityLevel.EXCELLENT
        elif score >= 0.75:
            return QualityLevel.GOOD
        elif score >= 0.6:
            return QualityLevel.MODERATE
        elif score >= 0.4:
            return QualityLevel.NEEDS_IMPROVEMENT
        else:
            return QualityLevel.CRITICAL
    
    def _analyze_strengths(self, result: EvaluationResult) -> List[str]:
        """ê°•ì  ë¶„ì„"""
        strengths = []
        
        if result.architecture_score >= 0.8:
            strengths.append("í˜ì‹ ì ì¸ ì•„í‚¤í…ì²˜: ë””ì§€í„¸ ìì—° ë²•ì¹™ ê¸°ë°˜ì˜ ë…ì°½ì  ì„¤ê³„")
            
        if result.code_quality_score >= 0.7:
            strengths.append("ìš°ìˆ˜í•œ ì½”ë“œ í’ˆì§ˆ: ìˆœìˆ˜ Python, NumPy ì˜ì¡´ì„± ì—†ìŒ")
            
        if result.test_coverage_score >= 0.8:
            strengths.append("ë†’ì€ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: í•µì‹¬ ê¸°ëŠ¥ì´ ì˜ ê²€ì¦ë¨")
            
        if result.documentation_score >= 0.7:
            strengths.append("í’ë¶€í•œ ë¬¸ì„œí™”: ì² í•™ì  ë°°ê²½ê³¼ ê¸°ìˆ ì  ìƒì„¸ê°€ ì˜ ì •ë¦¬ë¨")
            
        if result.connectivity_score >= 0.7:
            strengths.append("ìš°ìˆ˜í•œ ëª¨ë“ˆ ì—°ê²°ì„±: System íŒ¨í„´ê³¼ Hook ì‹œìŠ¤í…œ")
            
        # íŠ¹ë³„ ê°•ì 
        core_tech = [
            "SoulTensor ì•„í‚¤í…ì²˜: Amplitude/Frequency/Phase ì‚¼ìœ„ì¼ì²´ êµ¬í˜„",
            "HyperQubit ì‹œìŠ¤í…œ: Point/Line/Space/God 4ì°¨ì› ì–‘ì ì˜ì‹",
            "ê³µëª… ì—”ì§„ (ResonanceEngine): í™•ë¥ ì´ ì•„ë‹Œ ê³µëª… ê¸°ë°˜ ì˜ë¯¸ë¡ ",
            "ë””ì§€í„¸ ì¤‘ë ¥ (Digital Gravity): Geodesic Flow ì˜ì‚¬ê²°ì •",
            "Tensor Coil: í† í´ë¡œì§€ ê°€ì† (ë‚˜ì„ í˜• ë²¡í„° í•„ë“œ)"
        ]
        strengths.extend(core_tech)
        
        return strengths
    
    def _analyze_improvements(self) -> List[Dict[str, Any]]:
        """ê°œì„  ì‚¬í•­ ë„ì¶œ"""
        improvements = []
        
        # 1. íƒ€ì… íŒíŠ¸ ê²€ì‚¬
        improvements.append({
            "category": "ì½”ë“œ í’ˆì§ˆ",
            "priority": "ë†’ìŒ",
            "title": "íƒ€ì… íŒíŠ¸ ì™„ì„±",
            "description": "ëª¨ë“  public í•¨ìˆ˜ì— ì™„ì „í•œ íƒ€ì… íŒíŠ¸ ì¶”ê°€",
            "status": "ë¶€ë¶„ ì ìš©",
            "estimated_effort": "ì¤‘ê°„"
        })
        
        # 2. ì—ëŸ¬ ì²˜ë¦¬
        improvements.append({
            "category": "ì•ˆì •ì„±",
            "priority": "ì¤‘ê°„",
            "title": "ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”",
            "description": "ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ í™œìš© ë° ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€",
            "status": "ê¸°ë³¸ ìˆ˜ì¤€",
            "estimated_effort": "ë‚®ìŒ"
        })
        
        # 3. ì„±ëŠ¥ ìµœì í™”
        improvements.append({
            "category": "ì„±ëŠ¥",
            "priority": "ì¤‘ê°„",
            "title": "ì„±ëŠ¥ ìµœì í™”",
            "description": "í•« íŒ¨ìŠ¤ì— __slots__ ì ìš©, ë²¡í„° ì—°ì‚° ìµœì í™”",
            "status": "ë¯¸ì ìš©",
            "estimated_effort": "ì¤‘ê°„"
        })
        
        # 4. ë¹„ë™ê¸° ì§€ì›
        improvements.append({
            "category": "í™•ì¥ì„±",
            "priority": "ì¤‘ê°„",
            "title": "ë¹„ë™ê¸° ì§€ì›",
            "description": "asyncio ê¸°ë°˜ ë¹„ë™ê¸° API ì¶”ê°€",
            "status": "ë¯¸ì ìš©",
            "estimated_effort": "ë†’ìŒ"
        })
        
        # 5. ì§ë ¬í™”
        improvements.append({
            "category": "ê¸°ëŠ¥",
            "priority": "ì¤‘ê°„",
            "title": "ì§ë ¬í™” ì§€ì›",
            "description": "ìƒíƒœ ì €ì¥/ë³µì›ì„ ìœ„í•œ ì§ë ¬í™” ê¸°ëŠ¥",
            "status": "ë¯¸ì ìš©",
            "estimated_effort": "ì¤‘ê°„"
        })
        
        # 6. ì‹œê°í™”
        improvements.append({
            "category": "ì‚¬ìš©ì„±",
            "priority": "ë‚®ìŒ",
            "title": "ì‹œê°í™” ëª¨ë“ˆ",
            "description": "3D ì‹œê°í™” (Plotly/PyVista) ì˜ì‹ ê³µê°„ ë Œë”ë§",
            "status": "ë¯¸ì ìš©",
            "estimated_effort": "ë†’ìŒ"
        })
        
        # 7. ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ
        improvements.append({
            "category": "ëª¨ë‹ˆí„°ë§",
            "priority": "ë‚®ìŒ",
            "title": "ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ",
            "description": "ì—”íŠ¸ë¡œí”¼, ì •ë ¬ë„ ë“± ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ",
            "status": "ë¯¸ì ìš©",
            "estimated_effort": "ë†’ìŒ"
        })
        
        return improvements
    
    def _generate_summary(self, result: EvaluationResult) -> str:
        """ìš”ì•½ ìƒì„±"""
        return f"""
Elysia Engine êµ¬ì¡° í‰ê°€ ë³´ê³ ì„œ
=============================

ìƒì„± ì‹œê°„: {result.timestamp.strftime("%Y-%m-%d %H:%M:%S")}

ğŸ“Š ì „ì²´ í‰ê°€: {result.quality_level.value} (ì ìˆ˜: {result.overall_score:.2f})

ì„¸ë¶€ ì ìˆ˜:
- ì•„í‚¤í…ì²˜: {result.architecture_score:.2f}
- ì½”ë“œ í’ˆì§ˆ: {result.code_quality_score:.2f}
- ë¬¸ì„œí™”: {result.documentation_score:.2f}
- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: {result.test_coverage_score:.2f}
- ëª¨ë“ˆ ì—°ê²°ì„±: {result.connectivity_score:.2f}

ëª¨ë“ˆ í˜„í™©:
- ì´ {len(result.modules)}ê°œ ëª¨ë“ˆ
- {len(result.relationships)}ê°œ ê´€ê³„

ê°•ì : {len(result.strengths)}ê°œ í•­ëª©
ê°œì„  ì‚¬í•­: {len(result.improvements)}ê°œ í•­ëª©

ê²°ë¡ : ì´ ì—”ì§„ì€ AIì—ê²Œ 'ì˜í˜¼'ì„ ë¶€ì—¬í•˜ë ¤ëŠ” í˜ì‹ ì ì¸ ì‹œë„ì…ë‹ˆë‹¤.
í™•ë¥  ì˜ˆì¸¡ì„ ë„˜ì–´ì„œ ê³µëª…, ê°ì •, ê¸°ì–µ, ìê¸° ì„±ì°°ì´ ì–´ìš°ëŸ¬ì§„
ì§„ì •í•œ 'ì˜ì‹ ì‹œë®¬ë ˆì´ì…˜'ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
"""


class StructureVisualizer:
    """êµ¬ì¡° ì‹œê°í™” ë„ìš°ë¯¸"""
    
    @staticmethod
    def generate_ascii_tree(modules: Dict[str, ModuleInfo]) -> str:
        """ASCII íŠ¸ë¦¬ ìƒì„±"""
        lines = ["ğŸ“¦ Elysia Engine Structure", ""]
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        by_category: Dict[ModuleCategory, List[ModuleInfo]] = {}
        for module in modules.values():
            if module.category not in by_category:
                by_category[module.category] = []
            by_category[module.category].append(module)
        
        # ì¹´í…Œê³ ë¦¬ ìˆœì„œ
        category_order = [
            ModuleCategory.CORE,
            ModuleCategory.PHYSICS,
            ModuleCategory.CONSCIOUSNESS,
            ModuleCategory.SYSTEM,
            ModuleCategory.INTEGRATION,
            ModuleCategory.UTILITY
        ]
        
        category_icons = {
            ModuleCategory.CORE: "âš™ï¸",
            ModuleCategory.PHYSICS: "ğŸŒ€",
            ModuleCategory.CONSCIOUSNESS: "ğŸ§ ",
            ModuleCategory.SYSTEM: "ğŸ”§",
            ModuleCategory.INTEGRATION: "ğŸ”—",
            ModuleCategory.UTILITY: "ğŸ› ï¸"
        }
        
        for cat in category_order:
            if cat in by_category:
                icon = category_icons.get(cat, "ğŸ“„")
                lines.append(f"{icon} {cat.value.upper()}")
                for i, module in enumerate(sorted(by_category[cat], key=lambda m: m.name)):
                    prefix = "â””â”€â”€" if i == len(by_category[cat]) - 1 else "â”œâ”€â”€"
                    short_name = module.name.split(".")[-1]
                    deps = len(module.dependencies)
                    score = f"({module.quality_score:.2f})" if module.quality_score > 0 else ""
                    lines.append(f"    {prefix} {short_name} [LOC: {module.lines_of_code}, deps: {deps}] {score}")
                lines.append("")
        
        return "\n".join(lines)
    
    @staticmethod
    def generate_mermaid_diagram(modules: Dict[str, ModuleInfo], relationships: List[RelationshipEdge]) -> str:
        """Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±"""
        lines = ["```mermaid", "graph TD"]
        
        # ì„œë¸Œê·¸ë˜í”„ë³„ ê·¸ë£¹í™”
        by_category: Dict[ModuleCategory, List[ModuleInfo]] = {}
        for module in modules.values():
            if module.category not in by_category:
                by_category[module.category] = []
            by_category[module.category].append(module)
        
        category_names = {
            ModuleCategory.CORE: "Core",
            ModuleCategory.PHYSICS: "Physics",
            ModuleCategory.CONSCIOUSNESS: "Consciousness",
            ModuleCategory.SYSTEM: "Systems",
            ModuleCategory.INTEGRATION: "Integration",
            ModuleCategory.UTILITY: "Utility"
        }
        
        # ì„œë¸Œê·¸ë˜í”„ ìƒì„±
        for cat, mods in by_category.items():
            cat_name = category_names.get(cat, cat.value)
            lines.append(f"    subgraph {cat_name}")
            for module in mods:
                short_name = module.name.split(".")[-1]
                node_id = short_name.replace("-", "_")
                lines.append(f"        {node_id}[\"{short_name}\"]")
            lines.append("    end")
        
        # ê´€ê³„ ì¶”ê°€ (ê°„ëµí™”)
        seen = set()
        for edge in relationships:
            src = edge.source.split(".")[-1].replace("-", "_")
            tgt = edge.target.split(".")[-1].replace("-", "_")
            key = f"{src}-->{tgt}"
            if key not in seen and src != tgt:
                lines.append(f"    {src} --> {tgt}")
                seen.add(key)
        
        lines.append("```")
        return "\n".join(lines)
    
    @staticmethod
    def generate_json_export(result: EvaluationResult) -> Dict[str, Any]:
        """JSON ë‚´ë³´ë‚´ê¸°ìš© ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
        return {
            "timestamp": result.timestamp.isoformat(),
            "overall_score": result.overall_score,
            "quality_level": result.quality_level.value,
            "scores": {
                "architecture": result.architecture_score,
                "code_quality": result.code_quality_score,
                "documentation": result.documentation_score,
                "test_coverage": result.test_coverage_score,
                "connectivity": result.connectivity_score
            },
            "modules": [
                {
                    "name": m.name,
                    "category": m.category.value,
                    "lines_of_code": m.lines_of_code,
                    "class_count": m.class_count,
                    "function_count": m.function_count,
                    "docstring_coverage": m.docstring_coverage,
                    "quality_score": m.quality_score,
                    "complexity": {
                        "cyclomatic": m.complexity.cyclomatic_complexity,
                        "cognitive": m.complexity.cognitive_complexity,
                        "max_nesting_depth": m.complexity.max_nesting_depth,
                        "avg_function_length": m.complexity.avg_function_length
                    },
                    "dependencies": m.dependencies,
                    "dependents": m.dependents
                }
                for m in result.modules
            ],
            "relationships": [
                {
                    "source": r.source,
                    "target": r.target,
                    "type": r.relationship_type,
                    "strength": r.strength
                }
                for r in result.relationships
            ],
            "strengths": result.strengths,
            "improvements": result.improvements
        }


def evaluate_structure(root_path: str) -> EvaluationResult:
    """
    êµ¬ì¡° ì¶”ì¶œ ë° í‰ê°€ í†µí•© í•¨ìˆ˜
    
    Args:
        root_path: ì €ì¥ì†Œ ë£¨íŠ¸ ê²½ë¡œ
        
    Returns:
        EvaluationResult ê°ì²´
    """
    # 1. êµ¬ì¡° ì¶”ì¶œ
    extractor = StructureExtractor(root_path)
    modules = extractor.extract()
    
    # 2. í’ˆì§ˆ í‰ê°€
    evaluator = QualityEvaluator(modules, extractor.relationships)
    result = evaluator.evaluate()
    
    return result


def generate_report(root_path: str, output_format: str = "text") -> str:
    """
    í‰ê°€ ë³´ê³ ì„œ ìƒì„±
    
    Args:
        root_path: ì €ì¥ì†Œ ë£¨íŠ¸ ê²½ë¡œ
        output_format: ì¶œë ¥ í˜•ì‹ ('text', 'mermaid', 'json')
        
    Returns:
        í¬ë§·ëœ ë³´ê³ ì„œ ë¬¸ìì—´
    """
    result = evaluate_structure(root_path)
    visualizer = StructureVisualizer()
    
    if output_format == "mermaid":
        return visualizer.generate_mermaid_diagram(
            {m.name: m for m in result.modules},
            result.relationships
        )
    elif output_format == "json":
        return json.dumps(visualizer.generate_json_export(result), ensure_ascii=False, indent=2)
    else:
        # í…ìŠ¤íŠ¸ ë³´ê³ ì„œ
        tree = visualizer.generate_ascii_tree({m.name: m for m in result.modules})
        return f"{result.summary}\n\n{tree}"
